{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Import Lib & Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/brtsb88x4wz9n5kxdtldl3940000gn/T/ipykernel_90189/452374942.py:5: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_cts = pd.read_csv(\"Acar_data/concentrations.txt\", delim_whitespace=True)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "\n",
    "df_mat = sio.loadmat(\"Acar_data/EEM_NMR_LCMS.mat\")\n",
    "df_cts = pd.read_csv(\"Acar_data/concentrations.txt\", delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Val-Tyr-Val</th>\n",
       "      <th>Trp-Gly</th>\n",
       "      <th>Phe</th>\n",
       "      <th>Malto</th>\n",
       "      <th>Propanol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Val-Tyr-Val  Trp-Gly  Phe  Malto  Propanol\n",
       "1          5.0      0.0  0.0    0.0       0.0\n",
       "2          0.0      5.0  0.0    0.0       0.0\n",
       "3          0.0      0.0  5.0    0.0       0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'Y', 'X', 'Z'])\n",
      "('name', 'type', 'author', 'date', 'moddate', 'imagesize', 'imagemode', 'data', 'label', 'axisscale', 'imageaxisscale', 'title', 'class', 'include', 'classlookup', 'axistype', 'imageaxistype', 'description', 'userdata', 'datasetversion', 'history', 'uniqueid')\n"
     ]
    }
   ],
   "source": [
    "print(df_mat.keys())\n",
    "print(df_mat[\"X\"].dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted EEM data with shape (28, 251, 21)\n",
      "Extracted 3-way NMR data with shape (28, 13324, 8)\n",
      "Extracted LCMS data with shape (28, 168)\n"
     ]
    }
   ],
   "source": [
    "data_dic = {}\n",
    "dimensions = [\"X\", \"Y\", \"Z\"]\n",
    "for dim in dimensions:\n",
    "    mesurement_technique = df_mat[dim][\"name\"][0][0][0]\n",
    "    data = df_mat[dim][\"data\"][0][0]\n",
    "    data_dic[mesurement_technique] = data\n",
    "    print(f\"Extracted {mesurement_technique} data with shape {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Performing CP decomposition --------------------\n",
      "Tenseur shape avant CP: (28, 13324, 8)\n",
      "0. Shape du facteur 0 : ()\n",
      "[1. 1. 1.]\n",
      "1. Shape du facteur 1 : (28, 3)\n",
      "[array([[2771123.68126169, 1123300.40883946,  614127.12369003],\n",
      "       [-469476.82531928,   32392.8980954 , -164881.71149641],\n",
      "       [ 226634.977006  ,  422714.21112521,  -57268.22290384],\n",
      "       [2281649.45600227,  361289.64391343, 1425434.12319328],\n",
      "       [ 677473.52293271,  339838.60887797,  119542.00376569],\n",
      "       [1765591.19829086,  884329.47966739,  844133.1304138 ],\n",
      "       [2584885.73700723, 1353053.88278702,  621121.01841184],\n",
      "       [1284282.48092858,  857289.19089584,  340788.00510229],\n",
      "       [3680272.9797122 , 1572969.49420901, 1279351.60269393],\n",
      "       [1888226.35296774, 1314583.61364242,  256076.54189985],\n",
      "       [3728523.71576975, 1688894.42564266,  774864.52810753],\n",
      "       [ 917398.89237088,  871687.857425  ,   47602.59077615],\n",
      "       [1075726.74846673,  973518.23746692,   84689.46509751],\n",
      "       [3623855.70163284, 1786397.61195225,  821589.27916121],\n",
      "       [1700376.70403039,  861362.68674596,  654758.5752513 ],\n",
      "       [3819252.41088925, 1387568.63352878, 1602404.93549136],\n",
      "       [2145669.78665509, 1170237.99035989,  523313.85796772],\n",
      "       [1949563.24239066,  838488.49117456,  763963.26547396],\n",
      "       [4485178.72861722, 1430716.66656392, 1849075.81766435],\n",
      "       [2098502.44871942,  960835.35968872,  610861.30281128],\n",
      "       [4402262.90013952, 1464182.73942491, 1606752.06635136],\n",
      "       [2931040.1409188 , 1496842.44452995,  540700.77423614],\n",
      "       [3466453.8244482 , 1539011.50536685,  719145.77343558],\n",
      "       [1259133.62208828,  867240.68527529,  158777.53814541],\n",
      "       [1679958.80875216,  862113.84033312,  310793.78680568],\n",
      "       [5132224.24658847, 1793530.25065102, 1778010.71675511],\n",
      "       [3647034.51985599, 1542276.28206401, 1149681.0833075 ],\n",
      "       [2703405.11130745, 1206081.23286342,  730342.33666577]]), array([[0.01219388, 0.01018281, 0.01867619],\n",
      "       [0.01238786, 0.01032441, 0.01879853],\n",
      "       [0.0125867 , 0.01046257, 0.01895423],\n",
      "       ...,\n",
      "       [0.01721884, 0.02005485, 0.02488546],\n",
      "       [0.01700716, 0.0199099 , 0.02470816],\n",
      "       [0.01677149, 0.0197826 , 0.02447005]], shape=(13324, 3)), array([[-1.29016036,  3.03404733,  1.6716421 ],\n",
      "       [-1.14783111,  2.65227716,  1.51816905],\n",
      "       [-1.02419113,  2.32463585,  1.38088636],\n",
      "       [-0.91606062,  2.043607  ,  1.25843233],\n",
      "       [-0.82127505,  1.7997703 ,  1.14787541],\n",
      "       [-0.73789347,  1.5893899 ,  1.04858521],\n",
      "       [-0.66405811,  1.40639136,  0.95878178],\n",
      "       [-0.59840622,  1.24627917,  0.87728259]])]\n",
      "3\n",
      "Shape des scores: (28, 3)\n",
      "Tenseur shape avant CP: (28, 251, 21)\n",
      "0. Shape du facteur 0 : ()\n",
      "[1. 1.]\n",
      "1. Shape du facteur 1 : (28, 2)\n",
      "[array([[nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan]]), array([[nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan]]), array([[nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan],\n",
      "       [nan, nan]])]\n",
      "3\n",
      "Shape des scores: (28, 2)\n",
      "--------------------------------------------------\n",
      "Shape scores NMR: (28, 3)\n",
      "Shape scores EEM: (28, 2)\n",
      "Shape scores LCMS: (28, 5)\n",
      "Shape finale des features fusionnés: (28, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NMR_0</th>\n",
       "      <th>NMR_1</th>\n",
       "      <th>NMR_2</th>\n",
       "      <th>EEM_0</th>\n",
       "      <th>EEM_1</th>\n",
       "      <th>LCMS_0</th>\n",
       "      <th>LCMS_1</th>\n",
       "      <th>LCMS_2</th>\n",
       "      <th>LCMS_3</th>\n",
       "      <th>LCMS_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.771124e+06</td>\n",
       "      <td>1.123300e+06</td>\n",
       "      <td>614127.123690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10235.584220</td>\n",
       "      <td>-7136.174505</td>\n",
       "      <td>-4643.342190</td>\n",
       "      <td>856.156766</td>\n",
       "      <td>-785.105793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.694768e+05</td>\n",
       "      <td>3.239290e+04</td>\n",
       "      <td>-164881.711496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13954.243357</td>\n",
       "      <td>2954.078675</td>\n",
       "      <td>-6345.742206</td>\n",
       "      <td>-432.799853</td>\n",
       "      <td>-694.762541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.266350e+05</td>\n",
       "      <td>4.227142e+05</td>\n",
       "      <td>-57268.222904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13407.111172</td>\n",
       "      <td>-819.118841</td>\n",
       "      <td>6149.323188</td>\n",
       "      <td>408.030989</td>\n",
       "      <td>-538.782346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NMR_0         NMR_1          NMR_2  EEM_0  EEM_1        LCMS_0  \\\n",
       "0  2.771124e+06  1.123300e+06  614127.123690    NaN    NaN  10235.584220   \n",
       "1 -4.694768e+05  3.239290e+04 -164881.711496    NaN    NaN -13954.243357   \n",
       "2  2.266350e+05  4.227142e+05  -57268.222904    NaN    NaN -13407.111172   \n",
       "\n",
       "        LCMS_1       LCMS_2      LCMS_3      LCMS_4  \n",
       "0 -7136.174505 -4643.342190  856.156766 -785.105793  \n",
       "1  2954.078675 -6345.742206 -432.799853 -694.762541  \n",
       "2  -819.118841  6149.323188  408.030989 -538.782346  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "CP_RANK_NMR = 3\n",
    "CP_RANK_EEM = 2\n",
    "PCA_RANK_LCMS = 5\n",
    "\n",
    "\n",
    "# Factorisation CP pour NMR et EEM\n",
    "def cp_scores(tensor, rank):\n",
    "    \"\"\"\n",
    "    Applique PARAFAC à un tenseur 3D et retourne les scores des individus (mode 0).\n",
    "    \"\"\"\n",
    "    print(f\"Tenseur shape avant CP: {tensor.shape}\")\n",
    "\n",
    "    # Check que le mode 0 = individus (n = 28)\n",
    "    if tensor.shape[0] != 28:\n",
    "        raise ValueError(\n",
    "            \"Le mode 0 n'est pas celui des individus. Tenseur mal orienté.\"\n",
    "        )\n",
    "\n",
    "    # PARAFAC\n",
    "    # factors = parafac(tensor, rank=rank, init='svd', random_state=SEED)\n",
    "    factors = parafac(\n",
    "        tensor, rank=rank, n_iter_max=200, tol=1e-6, init=\"random\", random_state=SEED\n",
    "    )\n",
    "    for i, f in enumerate(factors):\n",
    "        print(f\"{i}. Shape du facteur {i} : {f[0].shape}\")\n",
    "\n",
    "    print(len(factors[1]))\n",
    "    print(f\"Shape des scores: {factors[1][0].shape}\")\n",
    "    return tl.to_numpy(factors[1][0])\n",
    "\n",
    "\n",
    "X_eem = data_dic[\"EEM\"]\n",
    "X_nmr = data_dic[\"3-way NMR\"]\n",
    "X_lcms = data_dic[\"LCMS\"]\n",
    "\n",
    "print(\"-\" * 20, \"Performing CP decomposition\", \"-\" * 20)\n",
    "\n",
    "scores_nmr = cp_scores(X_nmr, CP_RANK_NMR)\n",
    "scores_eem = cp_scores(X_eem, CP_RANK_EEM)\n",
    "\n",
    "#  PCA LCMS\n",
    "pca_lcms = PCA(n_components=PCA_RANK_LCMS, random_state=SEED)\n",
    "scores_lcms = pca_lcms.fit_transform(X_lcms)\n",
    "\n",
    "# Fusion\n",
    "if scores_nmr.shape[0] != scores_lcms.shape[0]:\n",
    "    scores_nmr = scores_nmr.T\n",
    "if scores_eem.shape[0] != scores_lcms.shape[0]:\n",
    "    scores_eem = scores_eem.T\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Shape scores NMR: {scores_nmr.shape}\")\n",
    "print(f\"Shape scores EEM: {scores_eem.shape}\")\n",
    "print(f\"Shape scores LCMS: {scores_lcms.shape}\")\n",
    "X_fused = np.hstack([scores_nmr, scores_eem, scores_lcms])\n",
    "print(f\"Shape finale des features fusionnés: {X_fused.shape}\")\n",
    "\n",
    "\n",
    "df_fused = pd.DataFrame(\n",
    "    data=X_fused,\n",
    "    columns=[f\"NMR_{i}\" for i in range(scores_nmr.shape[1])]\n",
    "    + [f\"EEM_{i}\" for i in range(scores_eem.shape[1])]\n",
    "    + [f\"LCMS_{i}\" for i in range(scores_lcms.shape[1])],\n",
    ")\n",
    "df_fused.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_eem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrations = pd.read_csv(\"Acar_data/concentrations.txt\", sep=r\"\\s+\", index_col=0)\n",
    "y = concentrations.values\n",
    "print(f\"Shape des concentrations (y): {y.shape}\")\n",
    "\n",
    "# Standardisation et régression Ridge\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_fused)\n",
    "\n",
    "alphas = np.logspace(-3, 3, 100)\n",
    "model = RidgeCV(alphas=alphas, cv=5)\n",
    "\n",
    "# Validation croisée\n",
    "scores = cross_val_score(model, X_scaled, y, cv=5, scoring=\"r2\")\n",
    "print(f\"R² moyen en validation croisée : {scores.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
